<!DOCTYPE html>
<html lang="en-US">

  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.3.0 -->
<title>Defining a Model | blog</title>
<meta property="og:title" content="Defining a Model" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/posts/tf_start_to_finish/model.html" />
<meta property="og:url" content="http://localhost:4000/posts/tf_start_to_finish/model.html" />
<meta property="og:site_name" content="blog" />
<script type="application/ld+json">
{"name":null,"description":null,"url":"http://localhost:4000/posts/tf_start_to_finish/model.html","headline":"Defining a Model","dateModified":null,"datePublished":null,"sameAs":null,"@type":"WebPage","author":null,"image":null,"publisher":null,"mainEntityOfPage":null,"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=4a6cb11caf3fc568d91e45d3e747880b225cb4d1">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name"><a href='/' style="color:white; text-decoration:none">TensorBits</a></h1>
      <h2 class="project-tagline"></h2>
      
    </section>

    <section class="main-content">
      <h1 id="part-4-defining-a-model">Part 4: Defining a Model</h1>

<div style="text-align: center">
    <a href="https://www.tensorflow.org/programmers_guide/estimators" target="_blank">TensorFlow Programmer's Guide -  Estimator</a><br />
    <a href="https://www.tensorflow.org/extend/estimators" target="_blank">TensorFlow Extend - Estimators</a><br />
</div>

<p>Now for the part you’ve all been waiting for - defining a model.</p>

<p>To build the model we are going to use one of TensorFlow’s new (as of version 1.1) <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator" target="_blank">Estimator API</a>.  Estimators accept as arguments the things we do want to handle ourselves:</p>
<ul>
  <li>a <code class="highlighter-rouge">model_fn</code> that defines the model’s logic</li>
  <li>a dictionary of hyperparameters that define things like the learning rate, dropout rate, etc.)</li>
</ul>

<p>and abstracts away the things that should be automatic:</p>
<ul>
  <li>writing TensorBoard logs</li>
  <li>saving checkpoints</li>
  <li>looping over batches of data</li>
  <li>exporting a servable model</li>
</ul>

<p>To create an Estimator we follow these steps:</p>
<ol>
  <li>Define the Estimator object</li>
  <li>Construct the model’s logic in a function model_fn</li>
  <li>Set parameters such as model_dir, config, and params</li>
</ol>

<p><span class="protip"><b>Tip: </b>I like to keep this model code in a separate python file, let’s call it <code class="highlighter-rouge">model.py</code>, that is imported from the main training script.  Since research usually involves trying several architecture variants, separate model files help keep all the subtle differences in order.  Later, we will see how to copy over the exact code that is used for each training run to make completely reproducible results.</span></p>

<p>To follow along with the running example, create a new file called <code class="highlighter-rouge">model.py</code>.</p>

<h2 id="defining-the-estimator-object">Defining the Estimator object</h2>
<p>Inside <code class="highlighter-rouge">model.py</code> I add one addition function <code class="highlighter-rouge">load_estimator</code> which handles both loading a new model (if <code class="highlighter-rouge">model_dir</code> is not speicified) and loads the Estimator’s most recent checkpoint found in <code class="highlighter-rouge">model_dir</code> if it is specified.  This is a nice abstraction to have if you are restarting training or have another script, say a visualization demo, where you want to load the trained model.</p>

<p><span class="protip"><b>Tip: </b>When an Estimator is initialized, it looks in <code class="highlighter-rouge">model_dir</code> and uses the latest saved checkpoint if it exists.  You create a new model by passing <code class="highlighter-rouge">model_dir=None</code>.</span></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
Constructs and returns a TensorFlow Estimator with the model function and parameters provided.  
If model_dir is specified and an existing checkpoint exists, the Estimator is initialized from the  
most recent checkpoint.  Otherwise, a new Estimator is initialized.

    Inputs:
        model_fn: function handle to function that defines the logic of the model
        model_dir: output directory where checkpoints and summary statistics will be stored 
        config: RunConfig object that contains runtime variables 
            (i.e. random seed, checkpoint frquency, etc.)
        params: dictionary of hyperparameters that need to be accessible inside model_fn
    Outputs:
        TensorFlow Estimator object that encapsulates your model
'''
def load_estimator(model_fn=None, model_dir=None, config=None, params=None):
    return tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, config=config, params=params)
</code></pre></div></div>

<h2 id="constructing-the-model-function">Constructing the Model Function</h2>
<p>Now, let’s define the core logic of the model, <code class="highlighter-rouge">model_fn</code>.</p>

<p>This function is called when:</p>
<ul>
  <li><b>Predicting:</b> predictions are computed and then immediately returned</li>
  <li><b>Evaluating:</b> predictions are made and evaluation metrics are computed but no step is taken with the optimizer</li>
  <li><b>Training:</b> predictions are made, evaluation metrics are computed, and optimization is performed</li>
</ul>

<p>For all projects we do this in a function with the following signature:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'''
Defines the model function passed into tf.estimator.  
This function defines the computational logic for the model.

Implementation:
    1. Define the model's computations with TensorFlow operations
    2. Generate predictions and return a prediction EstimatorSpec
    3. Define the loss function for training and evaluation
    4. Define the training operation and optimizer
    5. Return loss, train_op, eval_metric_ops in an EstimatorSpec

    Inputs:
        features: A dict containing the features passed to the model via input_fn
        labels: A Tensor containing the labels passed to the model via input_fn
        mode: One of the following tf.estimator.ModeKeys string values indicating
               the context in which the model_fn was invoked 
                  - tf.estimator.ModeKeys.TRAIN ---&gt; model.train()
                  - tf.estimator.ModeKeys.EVAL, ---&gt; model.evaluate()
                  - tf.estimator.ModeKeys.PREDICT -&gt; model.predict()

    Outputs:
        tf.EstimatorSpec that defines the model in different modes.
'''
def model(features, labels, mode, params):
    # 1. Define model structure
    
    # ...
    # convolutions, denses, and batch norms, oh my!
    # ...

    # 2. Generate predictions
    if mode == tf.estimator.ModeKeys.PREDICT:
        predictions = {'output_str': output_var} # alter this dictionary for your model
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)
    
    # 3. Define the loss functions
    loss = ...
    
    # 3.1 Additional metrics for monitoring
    eval_metric_ops = {"rmse": tf.metrics.root_mean_squared_error(
          tf.cast(labels, tf.float64), output)}
    
    # 4. Define optimizer
    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])
    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
    
    # 5. Return training/evaluation EstimatorSpec
    return EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)
    
</code></pre></div></div>

<p><span class="warning"><b>Warning:</b> The main gotchya in here is making sure to put your logic in the correct order.  In predict mode you don’t have access to the label so you should make predictions first and then return.  Then, after where you will return in predict mode, you can define the loss function and optimizer.</span></p>

<p>Here is a simple convolutional neural network for our running example:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="setting-additional-parameters">Setting Additional Parameters</h2>
<p>Before we’re done, we need to set a few final variables.</p>

<ul>
  <li>params: a dictionary of model hyperparameters that is accessible in <code class="highlighter-rouge">model_fn</code></li>
  <li>config: a tf.estimator.RunConfig object of runtime parameters</li>
  <li>output_dir: the output directory where Estimator will write summary statistics, training checkpoints, and the graph structure</li>
</ul>

<h3 id="params">params</h3>
<p>You may have noticed in the running example <code class="highlighter-rouge">model_fn</code> several arguments being pulled from the params dictionary.  This is a perfect place to store things like the learning rate for your optimizer, the number of layers in part of your network, the number of units in a layer, etc.</p>

<p>I also like defining <code class="highlighter-rouge">params</code> in <code class="highlighter-rouge">model.py</code> since the parameters are logically connected to the model logic and to keep the main training script clean.</p>

<p>For the running example let’s use the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>###################################
###   Defined inside model.py   ###
###################################
params = {
    layers = [
        {'num_outputs' : 10, 'kernel_size' : 3, 'stride' : 2, 'activation' : tf.nn.relu, 'regularizer' : tf.nn.l2_loss},
    ],
    learning_rate = 0.001
}
</code></pre></div></div>

<h3 id="config">config</h3>
<p>Not to be confused with <code class="highlighter-rouge">params</code>, <code class="highlighter-rouge">config</code> is a <a href="https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig" target="_blank">tf.estimator.RunConfig</a> object that contains parameters that affect the Estimator while it is running such as <code class="highlighter-rouge">tf_random_seed</code>, <code class="highlighter-rouge">save_summary_steps</code>, <code class="highlighter-rouge">keep_checkpoint_max</code>, etc.  Passing config to the Estimator is optional and mostly something you can avoid unless you need something fairly specific.</p>

<p>We don’t need this for the running example, but for completeness:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>config = tf.estimator.RunConfig(
    tf_random_seed=0,
    save_checkpoints_steps=250,
    save_checkpoints_secs=None,
    save_summary_steps=10,
)
</code></pre></div></div>

<h3 id="output_dir">output_dir</h3>
<p>This one is easy - pick some output directory where you want data related to training this Estimator to be saved.</p>

<p>For me, these are all in a results directory &lt;project&gt;/results/.  Make sure to add <code class="highlighter-rouge">results/</code> to your <code class="highlighter-rouge">.gitignore</code>.</p>

<p>I simply name the output directory by a timestamp of when the script is run.  You might modify this when testing different versions of a model (&lt;project&gt;/results/v1/…, &lt;project&gt;/results/v2/…, etc).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>################################################
###   Inside &lt;project&gt;/code/train_model.py   ###
################################################

import time, datetime

ts = time.time()
timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H-%M-%S')

output_dir = '../results/' + timestamp
</code></pre></div></div>

<h2 id="putting-it-all-together">Putting it All Together</h2>
<p>Now that everything we need is defined, we can create the Estimator from the main training script.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>################################################
###   Inside &lt;project&gt;/code/train_model.py   ###
################################################

from model import load_estimator, model_fn, params

estimator = load_estimator(model_fn=model_fn, output_dir=output_dir, config=config, params=params)
</code></pre></div></div>

<h2 id="improving-reproducibility">Improving Reproducibility</h2>
<p>For better reproducibility I use the following lines to copy over the main training script and the model file that defines the Estimator.  This makes everything much more straight-forward when comparing several slightly varying architectures. Technically you can look up the exact architecture of the model you ran in the <em>Graph</em> tab of TensorBoard, but I’ll take the bet you’d rather take a quick peek at the python file you wrote than dig 4 levels into the TensorBoard graph visualization.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>################################################
###   Inside &lt;project&gt;/code/train_model.py   ###
################################################

import os, shutil

# Find the path of the current running file (train script)
curr_path = os.path.realpath(__file__)

# Define the path of your factored out model.py file
model_file = '/some/path/model.py'

# Now copy the training script and the model file to 
#   output_dir -- the same directory specified when creating the Estimator
# Note: copy over more files if there are other important dependencies.
shutil.copy(curr_path, output_dir)
shutil.copy(model_path, output_dir)

</code></pre></div></div>

<p><span class="protip"><b>Tip: </b>If you are using Jupyter Notebooks (which you should be!), calling <code class="highlighter-rouge">tf.reset_default_graph()</code> before initializing your model is a good practice.  Doing this avoids creating extra variables and naming confusions.  One of your cells may look like: </span></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.reset_default_graph()
estimator = load_estimator(...)
</code></pre></div></div>

<p>And that’s it!  The data is ready, the model is fully defined, and we are ready to start training.</p>

<hr />

<h2 id="continue-reading">Continue Reading</h2>

<p><button onclick="location.href='model'" class="continue-links">Continue to Part 5</button>
In Part 5 we will train and evaluate the Estimator.</p>

<hr />

<div style="text-align: center;">
    <button onclick="location.href='introduction'" class="continue-links">Introduction</button>
    <button onclick="location.href='setup'" class="continue-links">Part 1: Setup</button>
    <button onclick="location.href='dataprep'" class="continue-links">Part 2: Preparing Data</button>
    <button onclick="location.href='dataload'" class="continue-links">Part 3: Consuming Data</button>
    <button onclick="location.href='model'" class="continue-links">Part 4: Defining a Model</button>
    <button onclick="location.href='traineval'" class="continue-links">Part 5: Training and Evaluating</button>
    <button onclick="location.href='deploy'" class="continue-links">Part 6: Exporting, Testing, and Deploying</button>
    <button onclick="location.href='summary'" class="continue-links">Part 7: All Together Now</button>
    <button onclick="location.href='references'" class="continue-links">Part 8: Furthur Reading and References</button>
</div>


      <footer class="site-footer">
        <div style="text-align: center">
          <span class="site-social-media">
            
              <a href="https://twitter.com/crosleythomas" style="padding:10px 20px" target="_blank">
                <i class="fa fa-twitter"></i> Twitter
              </a>
            
            
            
              <a href="https://github.com/crosleythomas" style="padding:10px 20px" target="_blank">
                <i class="fa fa-github"></i> GitHub
              </a>
            

            
              <a href="https://linkedin.com/in/crosleythomas" style="padding:10px 20px" target="_blank">
                <i class="fa fa-linkedin"></i> LinkedIn
              </a>
            

            
              <a href="https://www.facebook.com/crosleythomas" style="padding:10px 20px" target="_blank">
                <i class="fa fa-facebook"></i> Facebook
              </a>
            

            
              <a href="https://www.instagram.com/crosleythomas" style="padding:10px 20px" target="_blank">
                <i class="fa fa-instagram"></i> Instagram
              </a>
            
          </span>
          <br><br><br>
        </div>


        
          <span class="site-footer-owner"><a href="http://github.com/crosleythomas/blog">Blog</a> is maintained by <a href="http://github.com/crosleythomas">crosleythomas</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </section>

    
  </body>
</html>